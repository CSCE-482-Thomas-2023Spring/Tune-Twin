{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rDApkkwOtG_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291c7336-849a-4b88-bb14-dafde2e9470b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive so that training data can be used\n",
        "def mount_drive():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "mount_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Ih_0TDpsZsts"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "import pandas as pd\n",
        "\n",
        "song_data = pd.read_csv(\"/content/drive/Shareddrives/Cop Detectors /Class Work/song_data/tracks_features.csv\")"
      ],
      "metadata": {
        "id": "IXbUCjUP1Eqf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(song_data.columns)\n",
        "\n",
        "# process data to fit into feature set\n",
        "feature_list = ['acousticness',\n",
        "                'danceability',\n",
        "                'energy',\n",
        "                'key',\n",
        "                'liveness',\n",
        "                'loudness',\n",
        "                'tempo']\n",
        "features = song_data[feature_list]\n",
        "print(features.describe())\n",
        "\n",
        "# normalize data\n",
        "features = tf.keras.utils.normalize(features.values)\n",
        "\n",
        "# shuffle data\n",
        "np.random.shuffle(features)\n",
        "\n",
        "\n",
        "# reshape data into a training set\n",
        "slice_index = int(len(features)*0.8)\n",
        "x_train = features[:slice_index]\n",
        "x_test = features[slice_index:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNBHLuXQ1rZ7",
        "outputId": "c367127a-1277-4fb5-f731-6ce5d892b15a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'name', 'album', 'album_id', 'artists', 'artist_ids',\n",
            "       'track_number', 'disc_number', 'explicit', 'danceability', 'energy',\n",
            "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
            "       'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
            "       'time_signature', 'year', 'release_date'],\n",
            "      dtype='object')\n",
            "       acousticness  danceability        energy           key      liveness  \\\n",
            "count  1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06   \n",
            "mean   4.467511e-01  4.930565e-01  5.095363e-01  5.194151e+00  2.015994e-01   \n",
            "std    3.852014e-01  1.896694e-01  2.946839e-01  3.536731e+00  1.804591e-01   \n",
            "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "25%    3.760000e-02  3.560000e-01  2.520000e-01  2.000000e+00  9.680000e-02   \n",
            "50%    3.890000e-01  5.010000e-01  5.240000e-01  5.000000e+00  1.250000e-01   \n",
            "75%    8.610000e-01  6.330000e-01  7.660000e-01  8.000000e+00  2.450000e-01   \n",
            "max    9.960000e-01  1.000000e+00  1.000000e+00  1.100000e+01  1.000000e+00   \n",
            "\n",
            "           loudness         tempo  \n",
            "count  1.204025e+06  1.204025e+06  \n",
            "mean  -1.180870e+01  1.176344e+02  \n",
            "std    6.982132e+00  3.093705e+01  \n",
            "min   -6.000000e+01  0.000000e+00  \n",
            "25%   -1.525400e+01  9.405400e+01  \n",
            "50%   -9.791000e+00  1.167260e+02  \n",
            "75%   -6.717000e+00  1.370460e+02  \n",
            "max    7.234000e+00  2.489340e+02  \n",
            "(963220, 7)\n",
            "(240805, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised Model\n",
        "# In this case, an autoencoder.\n",
        "\n",
        "# We will take in the following features (for now):\n",
        "# acousticness (0.0 to 1.0)\n",
        "# danceability (0.0 to 1.0)\n",
        "# energy (0.0 to 1.0)\n",
        "# key (-1 to 11), 0 = C\n",
        "# liveness (0.0 to 1.0?)\n",
        "# loudness (-60dB to 0 dB)\n",
        "# tempo (BPM)\n",
        "\n",
        "\n",
        "\n",
        "# For now, using this dataset from Kaggle:\n",
        "# It has 1.2 million Spotify songs' features\n",
        "# https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs?resource=download\n",
        "\n",
        "\n",
        "# Each feature will be a node in the first layer\n",
        "# Each new layer will reduce the number of nodes by 1\n",
        "# So there will be a 7 node layer, then a 6 node layer, then 5, and so on # I'm not currently sure whether this approach is best for encoding, because\n",
        "# it could be the case that much information is lost if we go down to 1 layer,\n",
        "# to the point of it becoming useless.\n",
        "# Also, stepping down faster (like halving the number of nodes) might be better.\n",
        "# Then there will be a sequence of decoding the information back up to 7 dimensions\n",
        "# This is so that we can verify that the encoding maintained the original information\n",
        "# Otherwise we could not train the model weights.\n",
        "\n",
        "# We can play with and research different architectures.\n",
        "\n",
        "\n",
        "# using this resource: https://towardsdatascience.com/unsupervised-machine-learning-example-in-keras-8c8bf9e63ee0\n",
        "# and https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "# and MAINLY https://www.tensorflow.org/tutorials/generative/autoencoder\n",
        "\n",
        "# latent dimensions: The number of dimensions in the compressed representation\n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(7, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(5, activation='tanh'),\n",
        "        layers.Dense(5, activation='tanh'),\n",
        "        layers.Dense(4, activation='tanh'),\n",
        "        layers.Dense(4, activation='tanh'),\n",
        "        layers.Dense(3, activation='tanh'),\n",
        "        #layers.Dense(2, activation='tanh'),\n",
        "        #layers.Dense(1, activation='tanh'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "        #layers.Dense(1, activation='tanh'),\n",
        "        #layers.Dense(2, activation='tanh'),\n",
        "        layers.Dense(3, activation='tanh'),\n",
        "        layers.Dense(4, activation='tanh'),\n",
        "        layers.Dense(4, activation='tanh'),\n",
        "        layers.Dense(5, activation='tanh'),\n",
        "        layers.Dense(5, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(7, activation='tanh'),\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder()"
      ],
      "metadata": {
        "id": "flbPTmZcvzm9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', \n",
        "                    loss=losses.MeanAbsoluteError(),\n",
        "                    metrics=[[\"accuracy\",]])"
      ],
      "metadata": {
        "id": "Z8Ix2jn0gZxx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "7QUBVbKn4Dpk",
        "outputId": "1a923d4b-82c6-4e20-a00d-dc90b6527b3a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24081/24081 [==============================] - 189s 8ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
            "Epoch 2/10\n",
            " 7335/24081 [========>.....................] - ETA: 1:58 - loss: 0.0022 - accuracy: 0.9992"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-627d5ee6c17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m autoencoder.fit(x_train, x_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 validation_split=0.2)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m--> 133\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# A new cache key will be built later when saving ConcreteFunction because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# only active captures should be saved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     lookup_func_key, _ = function_context.make_cache_key((args, kwargs),\n\u001b[0m\u001b[1;32m    337\u001b[0m                                                          captures)\n\u001b[1;32m    338\u001b[0m     \u001b[0mconcrete_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_func_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/function_context.py\u001b[0m in \u001b[0;36mmake_cache_key\u001b[0;34m(args, captures)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mcaptures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0msignature_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInternalTracingContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   args_signature = trace_type.from_value(\n\u001b[0m\u001b[1;32m    134\u001b[0m       args, signature_context)\n\u001b[1;32m    135\u001b[0m   captures_dict_tracetype = trace_type.from_value(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/core/function/trace_type/trace_type_builder.py\u001b[0m in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    127\u001b[0m           named_tuple_type, tuple(from_value(c, context) for c in value))\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/core/function/trace_type/trace_type_builder.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m           named_tuple_type, tuple(from_value(c, context) for c in value))\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/core/function/trace_type/trace_type_builder.py\u001b[0m in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_legacy_signature\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraceType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupportsTracingProtocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_tracing_type__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/typing.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     (not callable(getattr(cls, attr, None)) or\n\u001b[1;32m   1152\u001b[0m                      getattr(instance, attr) is not None)\n\u001b[0;32m-> 1153\u001b[0;31m                     for attr in _get_protocol_attrs(cls)):\n\u001b[0m\u001b[1;32m   1154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/typing.py\u001b[0m in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__annotations__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_abc_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEXCLUDED_ATTRIBUTES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m                 \u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.evaluate(x_test, x_test)"
      ],
      "metadata": {
        "id": "5Y5CBtUqt6I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16822f28-2435-4f44-e140-7b02d0051b17"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7526/7526 [==============================] - 30s 4ms/step - loss: 0.0153 - accuracy: 0.9977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.015335426665842533, 0.9976620078086853]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_test))\n",
        "print(x_test[0])\n",
        "print(x_test[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn9GBMXK-1hx",
        "outputId": "1636b4fe-c166-4a16-83d9-c55db7c53e6b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240805\n",
            "[ 3.72553370e-03  5.02102166e-03  3.95888246e-03  4.82790544e-02\n",
            "  8.12697416e-04 -7.47520692e-02  9.96004939e-01]\n",
            "(7,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = autoencoder.encoder(x_test[:1000]).numpy()\n",
        "print(preds.shape)"
      ],
      "metadata": {
        "id": "o2HBNwft3NO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15a3c59-8f75-4099-ad0d-0bef2aba56ad"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: PCA (preferred) or t-SNE on the features + the outputted feature(s) \n",
        "# from the unsupervised model, for dimensionality reduction"
      ],
      "metadata": {
        "id": "GSqDT3yeXlXK"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Nearest Neighbor Search algorithm in feature space"
      ],
      "metadata": {
        "id": "3YWC_nZ4X3Av"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape = (x_train.shape[0], x_train.shape[1]))\n",
        "x = layers.Bidirectional(layers.LSTM(16))(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer = \"rmsprop\", loss = \"mse\", metrics = [\"mae\"])\n",
        "print(x_train.shape)\n",
        "history = model.fit(x_train, epochs = 10, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "tPM3jrAK1FXF",
        "outputId": "00a59e6d-d00b-432a-83cc-d3a427895baf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(963220, 7)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-d41103696f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 963220, 7), found shape=(None, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "-e86cU_fFaLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Pzmuiq6WAWma"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(preds, columns=['X','Y','Z'])"
      ],
      "metadata": {
        "id": "JTPAeTsyFZeP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_3d(df, x='X', y='Y', z='Z')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "K3acPG4RGk7e",
        "outputId": "7b35326a-3cfe-4bb9-8cf1-c94469d31983"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"4f4fa33e-a637-428a-95d9-e5486fa0a8b8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4f4fa33e-a637-428a-95d9-e5486fa0a8b8\")) {                    Plotly.newPlot(                        \"4f4fa33e-a637-428a-95d9-e5486fa0a8b8\",                        [{\"hovertemplate\":\"X=%{x}<br>Y=%{y}<br>Z=%{z}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"x\":[-0.5174742341041565,-0.5174797773361206,-0.5174744129180908,-0.5174636840820312,-0.5174990892410278,-0.5175080299377441,-0.5175106525421143,-0.5174624919891357,-0.5174561738967896,-0.5174635052680969,-0.5174899101257324,-0.5174632668495178,-0.5174537897109985,-0.5174923539161682,-0.5174863338470459,-0.5174655914306641,-0.5174663066864014,-0.5175098776817322,-0.5174636244773865,-0.5175063014030457,-0.517484724521637,-0.5174475312232971,-0.5174720287322998,-0.5174869298934937,-0.5175082087516785,-0.5174518823623657,-0.5174763798713684,-0.5174747705459595,-0.517514705657959,-0.517469584941864,-0.517510175704956,-0.5174993872642517,-0.5174592733383179,-0.5174729228019714,-0.5174803137779236,-0.5174736976623535,-0.5174617171287537,-0.5174480676651001,-0.5174668431282043,-0.5175250172615051,-0.5174866914749146,-0.5175147652626038,-0.517461359500885,-0.5174880027770996,-0.5174679756164551,-0.5174660086631775,-0.5174576044082642,-0.5174838900566101,-0.517465353012085,-0.5174714922904968,-0.5174652934074402,-0.5174721479415894,-0.5174505114555359,-0.5174960494041443,-0.5174819827079773,-0.5174731612205505,-0.5174674987792969,-0.517511248588562,-0.5174816250801086,-0.5174600481987,-0.5174951553344727,-0.5174755454063416,-0.5174552798271179,-0.5174943804740906,-0.5174801349639893,-0.5174985527992249,-0.5174701809883118,-0.5174626111984253,-0.517473042011261,-0.5175314545631409,-0.5174484848976135,-0.5174641013145447,-0.5174621343612671,-0.517474353313446,-0.5174915194511414,-0.5174818634986877,-0.5174594521522522,-0.5174639225006104,-0.5174521207809448,-0.5174848437309265,-0.5174736976623535,-0.5174598097801208,-0.5175007581710815,-0.5174615979194641,-0.5174632668495178,-0.5174833536148071,-0.5174685716629028,-0.5174636244773865,-0.5174773335456848,-0.5174661874771118,-0.5174779891967773,-0.5174956917762756,-0.5174837708473206,-0.517476499080658,-0.5174665451049805,-0.5174732804298401,-0.5174888968467712,-0.5174933075904846,-0.5174719095230103,-0.5174832344055176,-0.5174716114997864,-0.5174559354782104,-0.5174757242202759,-0.517464816570282,-0.5174859166145325,-0.5174536108970642,-0.5174584984779358,-0.5175133347511292,-0.5174785852432251,-0.5174497961997986,-0.5174872279167175,-0.5174999833106995,-0.517490565776825,-0.51748126745224,-0.5174533724784851,-0.5174705386161804,-0.5174750089645386,-0.5174800753593445,-0.5174759030342102,-0.5174701809883118,-0.5174561738967896,-0.517469584941864,-0.5174762606620789,-0.5174671411514282,-0.5174552798271179,-0.5174779295921326,-0.5174927115440369,-0.5174738168716431,-0.5174731612205505,-0.5174627304077148,-0.5174641013145447,-0.5174779891967773,-0.5174722671508789,-0.5175151228904724,-0.5174857974052429,-0.5174866914749146,-0.5174856185913086,-0.5175088047981262,-0.517490565776825,-0.5174844264984131,-0.5174685120582581,-0.5174619555473328,-0.5174585580825806,-0.5174661874771118,-0.5175233483314514,-0.5174970626831055,-0.517480731010437,-0.5174625515937805,-0.5174829363822937,-0.5175409317016602,-0.517485499382019,-0.5175320506095886,-0.5174708366394043,-0.5174830555915833,-0.5174769163131714,-0.5174915194511414,-0.5174852609634399,-0.5174945592880249,-0.517518162727356,-0.5174515843391418,-0.5174551606178284,-0.5174590945243835,-0.5174716114997864,-0.5174688100814819,-0.5174962878227234,-0.5174685120582581,-0.5174634456634521,-0.517469048500061,-0.5174558758735657,-0.5174728631973267,-0.5174654722213745,-0.5174680352210999,-0.5174630880355835,-0.517490029335022,-0.5175186395645142,-0.5174958109855652,-0.5174583196640015,-0.5174825191497803,-0.5174600481987,-0.5174741744995117,-0.5174636244773865,-0.5174837112426758,-0.5175036787986755,-0.517524778842926,-0.517468273639679,-0.5175076127052307,-0.5174509882926941,-0.5174791216850281,-0.5174925327301025,-0.5174909830093384,-0.517464816570282,-0.5174758434295654,-0.5174883604049683,-0.5174956917762756,-0.5174521207809448,-0.5174830555915833,-0.517487108707428,-0.5174633860588074,-0.5174777507781982,-0.5174562335014343,-0.5174659490585327,-0.5175189971923828,-0.517496645450592,-0.5174665451049805,-0.5174697041511536,-0.5174731612205505,-0.5174719095230103,-0.5174586772918701,-0.5174797177314758,-0.5174911618232727,-0.5175337791442871,-0.5174658298492432,-0.5174635648727417,-0.5174756050109863,-0.5174819231033325,-0.5174987316131592,-0.5175036787986755,-0.5174832344055176,-0.5174738168716431,-0.5174818634986877,-0.5174902677536011,-0.517480731010437,-0.5175241231918335,-0.5175018310546875,-0.5174562335014343,-0.5174780488014221,-0.5174697041511536,-0.5174865126609802,-0.5175282955169678,-0.5174633860588074,-0.5174555778503418,-0.5174954533576965,-0.5174838900566101,-0.5174648761749268,-0.5174657702445984,-0.5174614787101746,-0.5174586772918701,-0.5174598097801208,-0.5174598097801208,-0.5174639821052551,-0.5175150036811829,-0.517463743686676,-0.5174762606620789,-0.5174963474273682,-0.5174943208694458,-0.5174838900566101,-0.51748126745224,-0.5174857378005981,-0.5174678564071655,-0.5174601674079895,-0.5175074338912964,-0.5174590945243835,-0.517495334148407,-0.5174829363822937,-0.5175317525863647,-0.5174766778945923,-0.5174919962882996,-0.5174795985221863,-0.5174679160118103,-0.517480731010437,-0.517470121383667,-0.5174757242202759,-0.5174671411514282,-0.5174539685249329,-0.5174958109855652,-0.5175027847290039,-0.517464816570282,-0.5174902677536011,-0.5174825191497803,-0.517452597618103,-0.5174774527549744,-0.5174955725669861,-0.517469584941864,-0.5174766778945923,-0.5175032019615173,-0.5174600481987,-0.5174705982208252,-0.5174686908721924,-0.5174713730812073,-0.5175296068191528,-0.5175219178199768,-0.5174687504768372,-0.5175161361694336,-0.517475426197052,-0.5174598693847656,-0.5174922347068787,-0.5174645781517029,-0.5175292491912842,-0.5174693465232849,-0.5174810290336609,-0.5174964666366577,-0.5174738168716431,-0.5174585580825806,-0.5175320506095886,-0.5174600481987,-0.5174766778945923,-0.5175225734710693,-0.5174809098243713,-0.5174959897994995,-0.5174537897109985,-0.517476499080658,-0.5174981355667114,-0.5174723863601685,-0.5174720287322998,-0.5174682140350342,-0.5174581408500671,-0.517475426197052,-0.5174906849861145,-0.5174631476402283,-0.5174901485443115,-0.5174635052680969,-0.5174784064292908,-0.5174760222434998,-0.5174582600593567,-0.5174616575241089,-0.5174713730812073,-0.5174586772918701,-0.517480194568634,-0.5174547433853149,-0.5174897909164429,-0.5174875855445862,-0.5174585580825806,-0.5174799561500549,-0.5175003409385681,-0.5174736976623535,-0.5175176858901978,-0.5174881219863892,-0.5174621939659119,-0.5175012350082397,-0.5174983739852905,-0.5174841284751892,-0.517477810382843,-0.5174586772918701,-0.5174575448036194,-0.5174803733825684,-0.5175238847732544,-0.517515242099762,-0.517507791519165,-0.5174627304077148,-0.5174832344055176,-0.5174978971481323,-0.5174744129180908,-0.5174797773361206,-0.5174723863601685,-0.5174795985221863,-0.5174980163574219,-0.5174769163131714,-0.5174762606620789,-0.5174827575683594,-0.5174719095230103,-0.5174479484558105,-0.517470121383667,-0.5174790024757385,-0.5174922347068787,-0.5174545049667358,-0.517465353012085,-0.5174806118011475,-0.517512857913971,-0.5174887776374817,-0.5174520015716553,-0.5175154209136963,-0.5174779891967773,-0.5174903869628906,-0.5174763798713684,-0.5174573659896851,-0.5174621939659119,-0.5174694657325745,-0.5174937844276428,-0.5174654722213745,-0.5174593925476074,-0.5174617171287537,-0.5175042152404785,-0.517459511756897,-0.5174615383148193,-0.5174829363822937,-0.5174785852432251,-0.5174713730812073,-0.5174593925476074,-0.5174878835678101,-0.5174985527992249,-0.5174810290336609,-0.517507791519165,-0.5175133347511292,-0.5174598097801208,-0.5174517035484314,-0.5174810290336609,-0.5174888372421265,-0.5174583196640015,-0.5174820423126221,-0.5174933075904846,-0.51751708984375,-0.5174908638000488,-0.5174639225006104,-0.5174744725227356,-0.5174841284751892,-0.517485499382019,-0.517474353313446,-0.5174733996391296,-0.5174559354782104,-0.517490565776825,-0.5174845457077026,-0.5175113081932068,-0.5174708962440491,-0.5174602270126343,-0.517463743686676,-0.5174766778945923,-0.517464816570282,-0.5174705386161804,-0.5175012946128845,-0.5174565315246582,-0.5175138115882874,-0.5174538493156433,-0.5175009965896606,-0.5175237655639648,-0.5174615979194641,-0.5174612998962402,-0.5174566507339478,-0.5175063014030457,-0.5174688100814819,-0.5174663066864014,-0.5174782276153564,-0.5174601674079895,-0.5174709558486938,-0.5174528360366821,-0.5174803733825684,-0.5174880027770996,-0.5174678564071655,-0.5174702405929565,-0.5174815654754639,-0.5174719095230103,-0.517476499080658,-0.5174481868743896,-0.5174837112426758,-0.5175289511680603,-0.5174585580825806,-0.5174766778945923,-0.5174685716629028,-0.5174957513809204,-0.5174944996833801,-0.5174804925918579,-0.5175220370292664,-0.5174622535705566,-0.5174906849861145,-0.517471194267273,-0.517463207244873,-0.5174795985221863,-0.5174679160118103,-0.5175114274024963,-0.5174892544746399,-0.5174844264984131,-0.5174679160118103,-0.517494261264801,-0.5174615979194641,-0.5174806118011475,-0.5174856781959534,-0.5175004601478577,-0.517484724521637,-0.5174738764762878,-0.5174750089645386,-0.5174664258956909,-0.5175014138221741,-0.5175114870071411,-0.5174538493156433,-0.5174643993377686,-0.5174702405929565,-0.5174923539161682,-0.5174837112426758,-0.517474353313446,-0.5174747109413147,-0.517464280128479,-0.5174732208251953,-0.5175105929374695,-0.5174618363380432,-0.5174726843833923,-0.517511785030365,-0.5174869894981384,-0.517491340637207,-0.5174828171730042,-0.5174899697303772,-0.5174853801727295,-0.5174819231033325,-0.5175192952156067,-0.5174533724784851,-0.5174694061279297,-0.5174632668495178,-0.5175182223320007,-0.5174548029899597,-0.5174619555473328,-0.5174924731254578,-0.5175006985664368,-0.5174832344055176,-0.5174579620361328,-0.5174772143363953,-0.5174999237060547,-0.5174819827079773,-0.5174580216407776,-0.5174912214279175,-0.5174934267997742,-0.5175108313560486,-0.517492949962616,-0.5174545049667358,-0.5174758434295654,-0.5174940824508667,-0.5175047516822815,-0.5174773335456848,-0.5175192356109619,-0.5174601674079895,-0.517482340335846,-0.5174745917320251,-0.5174840092658997,-0.517542839050293,-0.5174767971038818,-0.5174658894538879,-0.517473578453064,-0.5174567699432373,-0.5174738764762878,-0.5174874067306519,-0.517465353012085,-0.5175154209136963,-0.5174692869186401,-0.5174651741981506,-0.5174599289894104,-0.5174949169158936,-0.5174577236175537,-0.5174685120582581,-0.5174686312675476,-0.5174897909164429,-0.5175021290779114,-0.5174749493598938,-0.5174534320831299,-0.5174760818481445,-0.5174674987792969,-0.5174530744552612,-0.5174767971038818,-0.5174850225448608,-0.5174759030342102,-0.5174904465675354,-0.5174934267997742,-0.5174680948257446,-0.5174615383148193,-0.517490565776825,-0.5174775719642639,-0.5174645185470581,-0.5174648761749268,-0.5174958109855652,-0.5174802541732788,-0.5174763798713684,-0.5174751281738281,-0.5174641609191895,-0.5174664855003357,-0.5174567699432373,-0.5175295472145081,-0.5174972414970398,-0.5174576640129089,-0.5174823999404907,-0.5174821019172668,-0.5175279974937439,-0.5174819231033325,-0.5174571871757507,-0.5174981355667114,-0.5174784064292908,-0.5174689292907715,-0.517475962638855,-0.5174838900566101,-0.5174652338027954,-0.5174614191055298,-0.5174882411956787,-0.5174775719642639,-0.5174834132194519,-0.5174779295921326,-0.5174708366394043,-0.5175013542175293,-0.5174884796142578,-0.5174745917320251,-0.5174569487571716,-0.5174723267555237,-0.5175131559371948,-0.5175064206123352,-0.5175270438194275,-0.5175021290779114,-0.5175005197525024,-0.5174775719642639,-0.5174842476844788,-0.5174612998962402,-0.5174673199653625,-0.5174781084060669,-0.5174770355224609,-0.5174588561058044,-0.5175060629844666,-0.5174576044082642,-0.5175333619117737,-0.5174760222434998,-0.5175142288208008,-0.5174538493156433,-0.5174985527992249,-0.5174921751022339,-0.5174745321273804,-0.5174539685249329,-0.517470121383667,-0.5174737572669983,-0.5174724459648132,-0.5174686312675476,-0.517507791519165,-0.5175356268882751,-0.5174646973609924,-0.5175182223320007,-0.5174934267997742,-0.5175167322158813,-0.5174883604049683,-0.51751708984375,-0.5174843072891235,-0.5175214409828186,-0.5174646973609924,-0.5174875259399414,-0.5175163149833679,-0.5175083875656128,-0.5174869894981384,-0.5174800753593445,-0.5174790024757385,-0.5175004601478577,-0.517465353012085,-0.5174680948257446,-0.5174588561058044,-0.5174825191497803,-0.5174640417098999,-0.5174744129180908,-0.5175095796585083,-0.5175068974494934,-0.5174903273582458,-0.5174914598464966,-0.5174823999404907,-0.5174921154975891,-0.5175090432167053,-0.5174833536148071,-0.5174841284751892,-0.5174772143363953,-0.5174788236618042,-0.517522931098938,-0.5174755454063416,-0.5174611210823059,-0.5174654722213745,-0.5174897313117981,-0.5174671411514282,-0.5174617767333984,-0.5174912214279175,-0.5175007581710815,-0.5175251364707947,-0.5174689292907715,-0.5174615979194641,-0.5174856185913086,-0.5175250768661499,-0.5174838900566101,-0.5174673795700073,-0.5174790024757385,-0.5174853801727295,-0.5174615979194641,-0.5174911022186279,-0.5174761414527893,-0.5174739956855774,-0.5174689292907715,-0.5174651741981506,-0.5174750089645386,-0.5174985527992249,-0.5174995064735413,-0.5174556970596313,-0.517471194267273,-0.5174915194511414,-0.5175105333328247,-0.5174782276153564,-0.5174542665481567,-0.5174931287765503,-0.5174814462661743,-0.5174898505210876,-0.5174935460090637,-0.5175000429153442,-0.5174699425697327,-0.5174534320831299,-0.5174668431282043,-0.5174619555473328,-0.5174884796142578,-0.5174824595451355,-0.5174840688705444,-0.5174691677093506,-0.5174853205680847,-0.5174958109855652,-0.5175240635871887,-0.5174823999404907,-0.517512321472168,-0.5175092816352844,-0.5174726843833923,-0.5175255537033081,-0.5174721479415894,-0.517491340637207,-0.5174996852874756,-0.5174654722213745,-0.5174820423126221,-0.517475426197052,-0.5174710154533386,-0.5175143480300903,-0.5174590945243835,-0.5175474286079407,-0.5174575448036194,-0.5174703598022461,-0.5174635052680969,-0.5174943208694458,-0.517473578453064,-0.5174759030342102,-0.5175089836120605,-0.5174553990364075,-0.5174654126167297,-0.5174762606620789,-0.5174607038497925,-0.5174935460090637,-0.5174705386161804,-0.5174674987792969,-0.517500638961792,-0.5174588561058044,-0.5174736976623535,-0.517457902431488,-0.5174850821495056,-0.5174767971038818,-0.5175224542617798,-0.5174654722213745,-0.5174556970596313,-0.5174699425697327,-0.517470121383667,-0.5174703598022461,-0.5174590945243835,-0.5175055861473083,-0.517512857913971,-0.5174636840820312,-0.5174674987792969,-0.5175091624259949,-0.5174725651741028,-0.517499566078186,-0.5174776911735535,-0.5174747109413147,-0.5174809098243713,-0.5174933075904846,-0.517457902431488,-0.5175179243087769,-0.517511785030365,-0.5174636244773865,-0.517490565776825,-0.5174539685249329,-0.5174490213394165,-0.5174728631973267,-0.5174974799156189,-0.517484724521637,-0.5175032615661621,-0.5174528360366821,-0.5175143480300903,-0.5174747705459595,-0.5174503922462463,-0.5174959897994995,-0.5174795389175415,-0.5174698233604431,-0.5174829363822937,-0.5174834728240967,-0.5174487829208374,-0.5174651145935059,-0.5174975991249084,-0.5174621939659119,-0.5174663066864014,-0.5174586772918701,-0.5174520611763,-0.5174726843833923,-0.5174756646156311,-0.5175115466117859,-0.5174852013587952,-0.5175060629844666,-0.5174594521522522,-0.517473042011261,-0.517470121383667,-0.5175104737281799,-0.5174726843833923,-0.5174719095230103,-0.5174473524093628,-0.5174701809883118,-0.5174868702888489,-0.5174921751022339,-0.5174984931945801,-0.5174862146377563,-0.5174754858016968,-0.5174773335456848,-0.5174814462661743,-0.5174815654754639,-0.5174851417541504,-0.5174688100814819,-0.5174906849861145,-0.5174927711486816,-0.5174779295921326,-0.5174716711044312,-0.5174553990364075,-0.5175029635429382,-0.5175053477287292,-0.517469584941864,-0.5174903869628906,-0.5175386667251587,-0.5174849629402161,-0.517501175403595,-0.5174533724784851,-0.5174800157546997,-0.5174654722213745,-0.5174732804298401,-0.5174562335014343,-0.517449140548706,-0.5174677968025208,-0.5174511671066284,-0.5174607038497925,-0.5174762606620789,-0.5174602270126343,-0.5174873471260071,-0.5174593329429626,-0.517462968826294,-0.5174623727798462,-0.51747065782547,-0.5174651741981506,-0.517458438873291,-0.5174524784088135,-0.5174636244773865,-0.5174833536148071,-0.5175055861473083,-0.5174776315689087,-0.5175182223320007,-0.5174622535705566,-0.5175164341926575,-0.5174607038497925,-0.5174864530563354,-0.5174788236618042,-0.517490029335022,-0.5175254344940186,-0.5174588561058044,-0.5174995064735413,-0.517473042011261,-0.5174815654754639,-0.5174650549888611,-0.5174800753593445,-0.5174635648727417,-0.5174649953842163,-0.5174673795700073,-0.5174975395202637,-0.5174731016159058,-0.5174599289894104,-0.5175002217292786,-0.5175037980079651,-0.5175058841705322,-0.5174678564071655,-0.517478346824646,-0.5174874663352966,-0.5174811482429504,-0.5174590945243835,-0.5174577236175537,-0.5174800157546997,-0.5174697041511536,-0.5174657106399536,-0.5174859166145325,-0.517487108707428,-0.5175084471702576,-0.5174826383590698,-0.5174694657325745,-0.5175142288208008,-0.5175073146820068,-0.5174683332443237,-0.5174509286880493,-0.5174536108970642,-0.5174915194511414,-0.5175068974494934,-0.5174799561500549,-0.5174624919891357,-0.5174672603607178,-0.5174861550331116,-0.5175063610076904,-0.5174798965454102,-0.5175003409385681,-0.5174792408943176,-0.517503559589386,-0.5174704790115356,-0.5174686312675476,-0.517469584941864,-0.5174896717071533,-0.5174556970596313,-0.5175141096115112,-0.5174767971038818,-0.5175113677978516,-0.5175385475158691,-0.5175187587738037,-0.5174462795257568,-0.5175003409385681,-0.517482340335846,-0.5174845457077026,-0.5175062417984009,-0.5174968838691711,-0.5174733996391296,-0.5174676179885864,-0.5174623727798462,-0.5174795389175415,-0.5174669623374939,-0.5174814462661743,-0.5174611210823059,-0.5174576044082642,-0.5174691677093506,-0.5174888968467712,-0.5174575448036194,-0.517475962638855,-0.5174583196640015,-0.5174487233161926,-0.5174542665481567,-0.5174887776374817,-0.5175310373306274,-0.5174654722213745,-0.5174878835678101,-0.5174809098243713,-0.5174864530563354,-0.5175184607505798,-0.5174691081047058,-0.5174955725669861,-0.5174787044525146,-0.5174782276153564,-0.5174574851989746,-0.517476499080658,-0.5174940228462219,-0.5174641013145447,-0.5174593925476074,-0.5174714922904968,-0.5175099968910217,-0.5174641609191895,-0.5174770355224609,-0.5174999833106995,-0.5174586176872253,-0.5174884796142578,-0.5174581408500671,-0.5174596905708313,-0.517475426197052,-0.5174710154533386,-0.5174816250801086,-0.5174530744552612,-0.5175308585166931,-0.517495334148407,-0.517458438873291,-0.5174854397773743,-0.5174607634544373,-0.5174685120582581,-0.5174818634986877,-0.5175029635429382,-0.5174999237060547,-0.5174785852432251,-0.5174903273582458,-0.5174844264984131,-0.5174919962882996,-0.5175106525421143,-0.5174616575241089,-0.5174726247787476,-0.5174551606178284,-0.5174934267997742,-0.5174623727798462,-0.517457902431488,-0.5175248384475708,-0.5174843668937683,-0.5175188183784485,-0.5174704194068909,-0.517474353313446,-0.51751708984375,-0.5175373554229736,-0.5174645185470581,-0.5174741148948669,-0.5175087451934814,-0.5174629092216492,-0.5175186395645142,-0.517487108707428,-0.5174816846847534,-0.5174726247787476,-0.5175358653068542,-0.5174729228019714,-0.5174861550331116,-0.5174685120582581,-0.5174863338470459,-0.517469584941864,-0.5174940228462219,-0.517486035823822,-0.5174698829650879,-0.5174791216850281,-0.5175153613090515,-0.5174592733383179,-0.5174603462219238,-0.5175011157989502,-0.5174697041511536,-0.5174766182899475,-0.5174885392189026,-0.5174859166145325,-0.5174745321273804,-0.5174573063850403,-0.5175228714942932,-0.5174720287322998,-0.5174658894538879,-0.5174609422683716,-0.5174732804298401,-0.5174742341041565,-0.5175104141235352,-0.5174881219863892],\"y\":[0.32203972339630127,0.32204821705818176,0.3220432698726654,0.3220226764678955,0.3220921754837036,0.32210224866867065,0.32211238145828247,0.3220224976539612,0.3220156729221344,0.3220193684101105,0.32207658886909485,0.3220207989215851,0.3220103979110718,0.32206961512565613,0.32206931710243225,0.3220182955265045,0.32202547788619995,0.3221053183078766,0.3220193684101105,0.3220990300178528,0.3220508098602295,0.32200145721435547,0.32203108072280884,0.322065144777298,0.32210540771484375,0.32200250029563904,0.32203754782676697,0.3220486342906952,0.3221099078655243,0.32203301787376404,0.322115421295166,0.32208648324012756,0.322022020816803,0.3220362365245819,0.32204893231391907,0.3220421373844147,0.3220229148864746,0.3219885230064392,0.3220195174217224,0.3221396505832672,0.3220641016960144,0.322118878364563,0.3220233619213104,0.3220589756965637,0.32203438878059387,0.3220222294330597,0.3220077157020569,0.32205748558044434,0.32203060388565063,0.3220243752002716,0.322017639875412,0.3220401406288147,0.32199665904045105,0.32208725810050964,0.322052538394928,0.32203853130340576,0.3220236599445343,0.32210105657577515,0.32205307483673096,0.32201114296913147,0.32207390666007996,0.3220421075820923,0.3220079243183136,0.322072833776474,0.3220607042312622,0.3220878541469574,0.3220297694206238,0.32202795147895813,0.32202833890914917,0.32214033603668213,0.3220009505748749,0.3220233619213104,0.32202544808387756,0.32203176617622375,0.3220673203468323,0.32205548882484436,0.32201316952705383,0.3220228850841522,0.3220108151435852,0.32204553484916687,0.3220362365245819,0.32202327251434326,0.3220840394496918,0.3220132887363434,0.32202497124671936,0.3220577538013458,0.322035551071167,0.32202276587486267,0.32203516364097595,0.32202666997909546,0.322051078081131,0.3220856189727783,0.3220594525337219,0.32205045223236084,0.3220340609550476,0.32203319668769836,0.3220648169517517,0.3220825493335724,0.3220408856868744,0.3220563530921936,0.32203879952430725,0.32201191782951355,0.3220430016517639,0.32203060388565063,0.3220519721508026,0.32201099395751953,0.3220178484916687,0.32210078835487366,0.32205313444137573,0.32200533151626587,0.32205700874328613,0.3220866024494171,0.32206737995147705,0.32205966114997864,0.3220115303993225,0.322030633687973,0.3220498859882355,0.32204946875572205,0.32205042243003845,0.322040855884552,0.3220120966434479,0.322024941444397,0.32205310463905334,0.3220268487930298,0.3220135569572449,0.32204630970954895,0.32208019495010376,0.3220363259315491,0.32203930616378784,0.32201388478279114,0.3220183253288269,0.3220500349998474,0.32202816009521484,0.3221110701560974,0.3220650553703308,0.3220544159412384,0.32205790281295776,0.3221128582954407,0.322078138589859,0.3220597803592682,0.32203468680381775,0.32202285528182983,0.3220234513282776,0.32202181220054626,0.3221299350261688,0.3220751881599426,0.322046160697937,0.32200533151626587,0.32204920053482056,0.32216349244117737,0.32206910848617554,0.32213878631591797,0.32203972339630127,0.3220584988594055,0.32203879952430725,0.3220801055431366,0.32204315066337585,0.3220784366130829,0.32212772965431213,0.3220101296901703,0.3220072090625763,0.3220105469226837,0.3220272362232208,0.32203441858291626,0.3220713436603546,0.32202428579330444,0.3220151364803314,0.3220292925834656,0.3220159113407135,0.322034627199173,0.3220294415950775,0.32203641533851624,0.32202741503715515,0.32206785678863525,0.3221200406551361,0.3220865726470947,0.32201704382896423,0.32204288244247437,0.32201600074768066,0.3220439851284027,0.32202014327049255,0.32206255197525024,0.32209259271621704,0.3221281170845032,0.32203927636146545,0.32209962606430054,0.32200637459754944,0.3220411539077759,0.3220701813697815,0.3220732808113098,0.3220299184322357,0.32203856110572815,0.32206112146377563,0.3220762610435486,0.32200706005096436,0.322060227394104,0.32205843925476074,0.32202574610710144,0.32204756140708923,0.3220152258872986,0.32203346490859985,0.32213127613067627,0.32208964228630066,0.32203516364097595,0.3220349848270416,0.3220408260822296,0.322028785943985,0.3220175504684448,0.3220469057559967,0.32206353545188904,0.322147399187088,0.32202550768852234,0.32202693819999695,0.3220428228378296,0.3220538794994354,0.3220803737640381,0.3220909535884857,0.3220497965812683,0.32204383611679077,0.32205164432525635,0.3220630884170532,0.32206225395202637,0.32213085889816284,0.32209259271621704,0.3220157027244568,0.32204121351242065,0.32202816009521484,0.3220682740211487,0.3221415877342224,0.3220186233520508,0.322005957365036,0.3220776915550232,0.32206499576568604,0.3220159411430359,0.3220250904560089,0.32201650738716125,0.3220154047012329,0.32201191782951355,0.3220163583755493,0.32201892137527466,0.32212430238723755,0.32202547788619995,0.3220382332801819,0.32208970189094543,0.3220844864845276,0.3220522701740265,0.32205191254615784,0.32206329703330994,0.3220195770263672,0.32201406359672546,0.32210028171539307,0.32201820611953735,0.3220852315425873,0.32206523418426514,0.3221401572227478,0.3220432996749878,0.3220800459384918,0.32204440236091614,0.3220321536064148,0.32205092906951904,0.32203519344329834,0.32203012704849243,0.3220142722129822,0.3220062553882599,0.3220664858818054,0.32209423184394836,0.3220183253288269,0.3220592141151428,0.3220464289188385,0.32200485467910767,0.32204800844192505,0.32208627462387085,0.32202932238578796,0.32204321026802063,0.3220899701118469,0.3220115602016449,0.32203611731529236,0.32203909754753113,0.3220454454421997,0.3221328854560852,0.3221181035041809,0.322035551071167,0.3221264183521271,0.3220469355583191,0.3220082223415375,0.32208219170570374,0.3220202922821045,0.3221462666988373,0.322035551071167,0.3220483362674713,0.3220711350440979,0.3220454454421997,0.32200828194618225,0.3221474289894104,0.32201460003852844,0.32204392552375793,0.32212451100349426,0.3220462203025818,0.3220777213573456,0.3220062851905823,0.32203924655914307,0.3220715820789337,0.32202887535095215,0.3220294415950775,0.322026789188385,0.32202088832855225,0.3220401406288147,0.32207733392715454,0.3220185935497284,0.3220677077770233,0.32201746106147766,0.3220546543598175,0.32204946875572205,0.32201385498046875,0.3220123052597046,0.3220406174659729,0.3220192492008209,0.3220583498477936,0.3220093548297882,0.3220755159854889,0.3220720589160919,0.3220190703868866,0.322044312953949,0.322081595659256,0.322040855884552,0.3221251666545868,0.3220726549625397,0.32202818989753723,0.3220892548561096,0.32207733392715454,0.3220577538013458,0.32203739881515503,0.32200559973716736,0.32201746106147766,0.3220597505569458,0.3221343159675598,0.3221137523651123,0.32211068272590637,0.322011262178421,0.32206180691719055,0.3220856189727783,0.3220325708389282,0.3220428228378296,0.3220318853855133,0.3220457434654236,0.3220825493335724,0.3220396339893341,0.3220338523387909,0.32206523418426514,0.3220325708389282,0.32199957966804504,0.32202818989753723,0.3220553994178772,0.32207751274108887,0.3220074772834778,0.322029709815979,0.3220500349998474,0.32211601734161377,0.32206591963768005,0.3220052123069763,0.3221101760864258,0.32205450534820557,0.32207900285720825,0.3220349848270416,0.32201650738716125,0.32201942801475525,0.3220379650592804,0.3220800757408142,0.3220336139202118,0.322020024061203,0.32201439142227173,0.32210060954093933,0.3220151662826538,0.3220120072364807,0.32204344868659973,0.32204577326774597,0.32202744483947754,0.32201817631721497,0.3220660090446472,0.32209035754203796,0.3220481276512146,0.32210126519203186,0.32215264439582825,0.32202231884002686,0.3220055103302002,0.32204318046569824,0.3220747709274292,0.3220175504684448,0.3220529556274414,0.3220805823802948,0.32212212681770325,0.3220559060573578,0.32202786207199097,0.32203564047813416,0.3220611810684204,0.3220687508583069,0.32203564047813416,0.32203060388565063,0.3220083713531494,0.3220774829387665,0.3220526874065399,0.32210877537727356,0.32202985882759094,0.322014719247818,0.32202333211898804,0.32205286622047424,0.3220214247703552,0.32202643156051636,0.3220871686935425,0.3220118582248688,0.3221117854118347,0.3220134973526001,0.3220865726470947,0.32213863730430603,0.3220234811306,0.322018563747406,0.32200801372528076,0.3220980167388916,0.322035551071167,0.32203108072280884,0.3220491111278534,0.32202115654945374,0.32203197479248047,0.32200887799263,0.32206031680107117,0.3220537006855011,0.3220292627811432,0.3220355808734894,0.32205504179000854,0.32203924655914307,0.3220483362674713,0.32200294733047485,0.3220474421977997,0.32214513421058655,0.3220163881778717,0.3220382630825043,0.32202088832855225,0.32206839323043823,0.32207685708999634,0.32205769419670105,0.32212355732917786,0.32202088832855225,0.3220614492893219,0.3220447599887848,0.3220170736312866,0.32205188274383545,0.3220324218273163,0.3221086263656616,0.3220556080341339,0.32204973697662354,0.32202839851379395,0.32207924127578735,0.3220132291316986,0.32205161452293396,0.32205089926719666,0.32207638025283813,0.3220626711845398,0.3220432698726654,0.3220459222793579,0.32202982902526855,0.32208943367004395,0.32211393117904663,0.32200250029563904,0.32202059030532837,0.32203006744384766,0.3220786452293396,0.32205575704574585,0.32203471660614014,0.3220349848270416,0.3220232427120209,0.32203447818756104,0.32210418581962585,0.32202211022377014,0.32204028964042664,0.3221115469932556,0.3220529556274414,0.32206645607948303,0.32206055521965027,0.32206735014915466,0.3220564126968384,0.32204195857048035,0.322127103805542,0.322002112865448,0.32202520966529846,0.32202622294425964,0.3221253752708435,0.32201507687568665,0.3220159113407135,0.32207152247428894,0.3220940828323364,0.32205209136009216,0.3220171332359314,0.32203543186187744,0.32209599018096924,0.32205644249916077,0.3220093250274658,0.32207217812538147,0.32207074761390686,0.32211294770240784,0.3220806419849396,0.3220140337944031,0.3220376968383789,0.32208237051963806,0.3220812976360321,0.32203537225723267,0.3221207857131958,0.3220122754573822,0.3220580220222473,0.3220352828502655,0.32205137610435486,0.3221542239189148,0.32204514741897583,0.3220221698284149,0.322046160697937,0.3220014274120331,0.32204630970954895,0.3220578134059906,0.32203057408332825,0.3221101760864258,0.3220230042934418,0.3220232427120209,0.3220217227935791,0.3220856189727783,0.3220124840736389,0.3220241367816925,0.3220341205596924,0.322062224149704,0.3220962882041931,0.32204508781433105,0.32200372219085693,0.32204940915107727,0.3220192790031433,0.32200631499290466,0.32204630970954895,0.32204997539520264,0.3220420479774475,0.32206133008003235,0.32207930088043213,0.32203546166419983,0.32202595472335815,0.32207468152046204,0.3220342993736267,0.3220178484916687,0.32202592492103577,0.3220852315425873,0.3220553994178772,0.3220394551753998,0.32205015420913696,0.32202669978141785,0.3220234215259552,0.3220144808292389,0.32214558124542236,0.32208332419395447,0.32201269268989563,0.3220553398132324,0.3220498859882355,0.3221401274204254,0.32205116748809814,0.3220164477825165,0.3220829367637634,0.32204023003578186,0.32202982902526855,0.3220371901988983,0.32205843925476074,0.32201942801475525,0.32201406359672546,0.322055846452713,0.3220546245574951,0.32205483317375183,0.32203415036201477,0.32202932238578796,0.32208895683288574,0.32207149267196655,0.3220377564430237,0.32201430201530457,0.322037935256958,0.3221081793308258,0.3220958709716797,0.32213276624679565,0.32208868861198425,0.3220835328102112,0.3220407962799072,0.3220680356025696,0.3220187723636627,0.3220333755016327,0.32204195857048035,0.32205504179000854,0.32201746106147766,0.32209545373916626,0.32200250029563904,0.32214874029159546,0.32204827666282654,0.32211533188819885,0.32200732827186584,0.3220877945423126,0.3220796287059784,0.3220258057117462,0.32200586795806885,0.3220299482345581,0.32204651832580566,0.3220401704311371,0.3220394551753998,0.3221043646335602,0.32214951515197754,0.32202470302581787,0.3221285939216614,0.3220837116241455,0.3221074342727661,0.32205817103385925,0.3221171796321869,0.32206881046295166,0.32213345170021057,0.32202431559562683,0.32205823063850403,0.32211288809776306,0.32209381461143494,0.3220530152320862,0.32204827666282654,0.32204195857048035,0.3220856189727783,0.32201942801475525,0.32202306389808655,0.3220100700855255,0.3220408260822296,0.32203125953674316,0.3220398724079132,0.3221074342727661,0.32210636138916016,0.3220756947994232,0.32207706570625305,0.32204586267471313,0.3220718502998352,0.3220943212509155,0.3220609128475189,0.32205817103385925,0.32204169034957886,0.3220447599887848,0.322127103805542,0.32204434275627136,0.322013795375824,0.32202571630477905,0.322064071893692,0.3220190703868866,0.3220157027244568,0.32207226753234863,0.3220837414264679,0.3221300542354584,0.3220323324203491,0.3220217525959015,0.322067528963089,0.32213205099105835,0.32206034660339355,0.32202237844467163,0.3220553994178772,0.3220559060573578,0.3220151662826538,0.32205986976623535,0.3220495283603668,0.3220442235469818,0.3220289647579193,0.3220160901546478,0.32202795147895813,0.32208943367004395,0.32207992672920227,0.3220122158527374,0.3220338523387909,0.3220811188220978,0.32211536169052124,0.322042852640152,0.32199662923812866,0.3220711052417755,0.3220423758029938,0.32206493616104126,0.3220687508583069,0.32209038734436035,0.32202574610710144,0.32200801372528076,0.32202643156051636,0.3220202922821045,0.32205188274383545,0.3220573663711548,0.3220432996749878,0.3220386207103729,0.32204926013946533,0.32206499576568604,0.32213959097862244,0.3220615088939667,0.32211804389953613,0.32210686802864075,0.32204538583755493,0.3221258521080017,0.3220435380935669,0.3220745623111725,0.3220899999141693,0.32201629877090454,0.32206404209136963,0.3220421373844147,0.3220367729663849,0.32210877537727356,0.3220089375972748,0.3221607506275177,0.32201269268989563,0.32203784584999084,0.32202666997909546,0.32207170128822327,0.3220458924770355,0.3220420479774475,0.3221096992492676,0.32200518250465393,0.3220190107822418,0.3220459520816803,0.3220156729221344,0.3220783770084381,0.3220319151878357,0.3220243752002716,0.32209229469299316,0.32201695442199707,0.32203373312950134,0.3220110535621643,0.32205355167388916,0.32204070687294006,0.3221302330493927,0.32202479243278503,0.3220132887363434,0.3220295011997223,0.3220408856868744,0.32202598452568054,0.3220103681087494,0.3221060633659363,0.3221089839935303,0.32201582193374634,0.32202741503715515,0.3220994174480438,0.32204630970954895,0.32209253311157227,0.3220534920692444,0.3220292627811432,0.32204964756965637,0.3220711946487427,0.32200849056243896,0.3221251666545868,0.3221038281917572,0.3220151364803314,0.3220779299736023,0.3220108151435852,0.3220008909702301,0.3220384418964386,0.3220899999141693,0.32205721735954285,0.3220987319946289,0.3220076858997345,0.3221132755279541,0.3220439851284027,0.322005033493042,0.322078675031662,0.3220478892326355,0.3220399022102356,0.3220539391040802,0.3220570683479309,0.3220026195049286,0.32202112674713135,0.3220788538455963,0.32201719284057617,0.32201722264289856,0.32200887799263,0.3220067024230957,0.32204562425613403,0.3220405876636505,0.32211217284202576,0.32205814123153687,0.3221055567264557,0.3220137357711792,0.32204335927963257,0.3220424950122833,0.3220940828323364,0.32204630970954895,0.322031706571579,0.3219994306564331,0.3220374286174774,0.3220663368701935,0.3220686614513397,0.32207757234573364,0.3220590054988861,0.32203394174575806,0.32204556465148926,0.32205817103385925,0.3220508098602295,0.3220652639865875,0.3220207989215851,0.3220635652542114,0.3220694959163666,0.32204553484916687,0.32203423976898193,0.322005033493042,0.3220836818218231,0.3220900893211365,0.32202666997909546,0.3220742642879486,0.3221571147441864,0.32206299901008606,0.32208698987960815,0.3220052421092987,0.3220568597316742,0.322022944688797,0.3220365345478058,0.32200559973716736,0.3219970762729645,0.3220263719558716,0.32200345396995544,0.32202431559562683,0.32204651832580566,0.3220168650150299,0.32205748558044434,0.32201871275901794,0.3220287263393402,0.32202303409576416,0.3220435678958893,0.32202064990997314,0.32200887799263,0.32201069593429565,0.3220178484916687,0.32206645607948303,0.3220984935760498,0.3220420479774475,0.3221179246902466,0.3220178484916687,0.3221129775047302,0.32202205061912537,0.3220616579055786,0.32204943895339966,0.3220672011375427,0.3221164643764496,0.32201912999153137,0.32209551334381104,0.3220360279083252,0.3220582604408264,0.3220227360725403,0.3220472037792206,0.32201334834098816,0.3220294713973999,0.322033166885376,0.3220764398574829,0.3220444321632385,0.3220219016075134,0.3220798075199127,0.32210037112236023,0.3221047520637512,0.32202306389808655,0.3220426142215729,0.3220656216144562,0.3220553398132324,0.32201772928237915,0.3220164179801941,0.3220529556274414,0.32203972339630127,0.3220239579677582,0.3220566213130951,0.3220624327659607,0.322107195854187,0.32205042243003845,0.32204246520996094,0.3221088647842407,0.3221098780632019,0.3220202326774597,0.32200151681900024,0.32200607657432556,0.32206642627716064,0.3221066892147064,0.32204195857048035,0.32201850414276123,0.32203546166419983,0.32206323742866516,0.3220959007740021,0.3220580816268921,0.3220910429954529,0.32203811407089233,0.32209572196006775,0.32203152775764465,0.32202574610710144,0.32202956080436707,0.3220648467540741,0.3220124840736389,0.3221229612827301,0.32204222679138184,0.3221060037612915,0.32215043902397156,0.32212334871292114,0.32199400663375854,0.3220973312854767,0.3220479190349579,0.322051078081131,0.322103887796402,0.3220781981945038,0.3220422565937042,0.3220239281654358,0.3220168650150299,0.32204389572143555,0.32202136516571045,0.3220541179180145,0.3220162093639374,0.322017639875412,0.3220271170139313,0.32207685708999634,0.3220175504684448,0.3220385015010834,0.3220120072364807,0.32199573516845703,0.32200366258621216,0.3220696747303009,0.3221352696418762,0.3220115005970001,0.3220638632774353,0.3220604658126831,0.32205796241760254,0.3221140503883362,0.32202741503715515,0.3220759928226471,0.3220447897911072,0.32204344868659973,0.3220175504684448,0.32203859090805054,0.32207050919532776,0.32201915979385376,0.3220145106315613,0.32203954458236694,0.32209867238998413,0.3220227360725403,0.3220520317554474,0.3220828175544739,0.32201385498046875,0.32205837965011597,0.3220202326774597,0.32202020287513733,0.3220497667789459,0.3220335841178894,0.32205432653427124,0.32200372219085693,0.32213878631591797,0.32207199931144714,0.32201018929481506,0.3220503330230713,0.32201075553894043,0.3220333755016327,0.3220630884170532,0.3220874071121216,0.3220936954021454,0.3220398724079132,0.32205864787101746,0.32205700874328613,0.322075217962265,0.3220982849597931,0.3220188021659851,0.32203400135040283,0.32200220227241516,0.3220738470554352,0.32201892137527466,0.3220116198062897,0.32214152812957764,0.32206055521965027,0.32211834192276,0.3220299482345581,0.32204368710517883,0.3221123218536377,0.3221477270126343,0.3220217227935791,0.3220483362674713,0.32210198044776917,0.322024941444397,0.32211583852767944,0.32206234335899353,0.3220464587211609,0.32204508781433105,0.32215040922164917,0.32204669713974,0.32206395268440247,0.3220328688621521,0.32206693291664124,0.32203301787376404,0.32207614183425903,0.32204946875572205,0.3220216631889343,0.32205379009246826,0.3221067786216736,0.322009414434433,0.32201117277145386,0.3220967650413513,0.32202842831611633,0.3220387399196625,0.32206472754478455,0.32206207513809204,0.32204514741897583,0.3220044672489166,0.32212498784065247,0.32203179597854614,0.32202470302581787,0.32201799750328064,0.3220270276069641,0.3220449388027191,0.32211044430732727,0.32205918431282043],\"z\":[-0.8034367561340332,-0.8034436106681824,-0.8034377098083496,-0.8034234642982483,-0.8034710884094238,-0.8034812211990356,-0.803486168384552,-0.8034223318099976,-0.8034152388572693,-0.8034223914146423,-0.8034594058990479,-0.8034225702285767,-0.8034119606018066,-0.8034597039222717,-0.8034544587135315,-0.8034239411354065,-0.8034263849258423,-0.8034836649894714,-0.8034225106239319,-0.803479015827179,-0.8034483790397644,-0.8034042716026306,-0.8034326434135437,-0.8034538626670837,-0.803482174873352,-0.8034082651138306,-0.8034380674362183,-0.8034394383430481,-0.8034888505935669,-0.8034310340881348,-0.8034865260124207,-0.8034698367118835,-0.8034194111824036,-0.8034347295761108,-0.8034440875053406,-0.803436815738678,-0.8034217357635498,-0.803401529788971,-0.8034251928329468,-0.8035052418708801,-0.8034535050392151,-0.8034912943840027,-0.8034216165542603,-0.803453266620636,-0.8034300804138184,-0.8034253120422363,-0.8034144639968872,-0.8034494519233704,-0.8034268617630005,-0.803430438041687,-0.8034234642982483,-0.8034350872039795,-0.8034056425094604,-0.803467333316803,-0.8034465909004211,-0.8034354448318481,-0.8034268617630005,-0.8034836649894714,-0.8034464120864868,-0.803417444229126,-0.8034632205963135,-0.8034384250640869,-0.8034125566482544,-0.8034622073173523,-0.8034470081329346,-0.8034695982933044,-0.8034307956695557,-0.8034239411354065,-0.8034327626228333,-0.8035107851028442,-0.8034050464630127,-0.8034239411354065,-0.8034228682518005,-0.8034347891807556,-0.8034583330154419,-0.8034471869468689,-0.803417444229126,-0.8034236431121826,-0.8034105896949768,-0.8034471869468689,-0.8034353852272034,-0.8034202456474304,-0.8034704327583313,-0.8034192323684692,-0.8034237027168274,-0.8034490346908569,-0.8034308552742004,-0.8034234046936035,-0.8034381866455078,-0.8034265041351318,-0.8034427165985107,-0.8034665584564209,-0.8034498691558838,-0.8034414052963257,-0.8034287095069885,-0.8034342527389526,-0.8034554719924927,-0.8034638166427612,-0.8034350872039795,-0.8034485578536987,-0.8034343123435974,-0.8034141659736633,-0.8034387826919556,-0.8034263849258423,-0.8034497499465942,-0.8034119606018066,-0.8034178018569946,-0.8034853935241699,-0.8034438490867615,-0.8034071922302246,-0.80345219373703,-0.8034704923629761,-0.803457498550415,-0.8034477233886719,-0.8034117817878723,-0.8034312129020691,-0.8034399151802063,-0.8034440875053406,-0.8034408688545227,-0.8034335374832153,-0.8034144043922424,-0.8034290075302124,-0.8034418225288391,-0.8034273982048035,-0.803413987159729,-0.8034414649009705,-0.8034626841545105,-0.8034355640411377,-0.803435742855072,-0.8034203052520752,-0.8034226298332214,-0.8034425377845764,-0.8034321069717407,-0.803489625453949,-0.8034529685974121,-0.8034510612487793,-0.803450882434845,-0.8034846782684326,-0.8034603595733643,-0.8034504652023315,-0.8034306168556213,-0.8034219145774841,-0.803419291973114,-0.8034253120422363,-0.8035012483596802,-0.8034650087356567,-0.8034439086914062,-0.8034180402755737,-0.8034465909004211,-0.8035246729850769,-0.8034536838531494,-0.803510844707489,-0.803433895111084,-0.8034490346908569,-0.8034387826919556,-0.8034616112709045,-0.803446888923645,-0.8034638166427612,-0.8034963011741638,-0.803409993648529,-0.803412139415741,-0.8034164309501648,-0.8034312129020691,-0.8034308552742004,-0.8034634590148926,-0.8034278750419617,-0.8034212589263916,-0.8034296631813049,-0.803415060043335,-0.8034343123435974,-0.8034265637397766,-0.8034305572509766,-0.8034241795539856,-0.8034572601318359,-0.8034946918487549,-0.8034669160842896,-0.803417444229126,-0.8034445643424988,-0.8034186959266663,-0.8034377098083496,-0.8034226894378662,-0.8034506440162659,-0.8034751415252686,-0.8035020232200623,-0.8034315705299377,-0.803480327129364,-0.8034083843231201,-0.8034411668777466,-0.8034599423408508,-0.8034594655036926,-0.803426206111908,-0.8034377098083496,-0.8034541606903076,-0.8034642934799194,-0.8034096360206604,-0.8034493327140808,-0.8034523129463196,-0.8034239411354065,-0.80344158411026,-0.8034152388572693,-0.8034281134605408,-0.8034979701042175,-0.8034684658050537,-0.8034290671348572,-0.8034316301345825,-0.8034360408782959,-0.8034318685531616,-0.8034179210662842,-0.803443193435669,-0.8034570813179016,-0.8035145401954651,-0.8034259080886841,-0.8034243583679199,-0.803438663482666,-0.8034468293190002,-0.803467869758606,-0.8034748435020447,-0.803446888923645,-0.8034374117851257,-0.8034462332725525,-0.8034562468528748,-0.803447961807251,-0.8035022020339966,-0.8034735918045044,-0.8034152984619141,-0.8034402132034302,-0.8034298419952393,-0.8034543991088867,-0.803508460521698,-0.8034220933914185,-0.8034122586250305,-0.803464412689209,-0.803451418876648,-0.8034226894378662,-0.8034258484840393,-0.8034198880195618,-0.8034173846244812,-0.803417444229126,-0.8034185171127319,-0.8034226894378662,-0.8034928441047668,-0.8034241795539856,-0.8034380674362183,-0.8034682273864746,-0.8034650683403015,-0.8034481406211853,-0.8034458160400391,-0.8034524321556091,-0.803426206111908,-0.8034183382987976,-0.803480327129364,-0.8034183979034424,-0.8034661412239075,-0.8034505844116211,-0.8035110235214233,-0.803439736366272,-0.8034619092941284,-0.8034423589706421,-0.8034294247627258,-0.803445041179657,-0.8034321069717407,-0.8034355640411377,-0.8034241795539856,-0.803411066532135,-0.8034617304801941,-0.8034748435020447,-0.8034232258796692,-0.8034552335739136,-0.8034455180168152,-0.8034095168113708,-0.8034415245056152,-0.8034666180610657,-0.8034300804138184,-0.8034396171569824,-0.8034740686416626,-0.8034173846244812,-0.8034326434135437,-0.8034318089485168,-0.803435742855072,-0.803507387638092,-0.8034970760345459,-0.8034309148788452,-0.8034942150115967,-0.8034394383430481,-0.8034165501594543,-0.8034626841545105,-0.8034235239028931,-0.8035104870796204,-0.803431510925293,-0.8034445643424988,-0.8034634590148926,-0.8034378886222839,-0.8034152984619141,-0.8035131692886353,-0.8034183382987976,-0.8034399151802063,-0.803499162197113,-0.803443968296051,-0.8034647107124329,-0.8034108877182007,-0.8034384846687317,-0.8034650683403015,-0.803432285785675,-0.803432285785675,-0.8034282326698303,-0.8034181594848633,-0.8034377098083496,-0.8034602403640747,-0.8034219145774841,-0.8034572601318359,-0.8034219741821289,-0.8034440875053406,-0.8034406900405884,-0.8034164905548096,-0.8034190535545349,-0.803434431552887,-0.8034183382987976,-0.8034464716911316,-0.8034125566482544,-0.8034589886665344,-0.8034562468528748,-0.8034180998802185,-0.8034427165985107,-0.8034694194793701,-0.8034365177154541,-0.8034952878952026,-0.8034568428993225,-0.8034235835075378,-0.8034722208976746,-0.8034667372703552,-0.8034496903419495,-0.803439199924469,-0.8034148216247559,-0.8034167885780334,-0.8034470677375793,-0.8035028576850891,-0.803490400314331,-0.803483247756958,-0.8034197688102722,-0.8034499883651733,-0.8034684658050537,-0.8034349679946899,-0.8034421801567078,-0.8034331202507019,-0.8034428358078003,-0.803467869758606,-0.8034389615058899,-0.8034369349479675,-0.8034504055976868,-0.803432822227478,-0.8034042119979858,-0.8034303188323975,-0.8034447431564331,-0.8034616112709045,-0.8034116625785828,-0.8034266233444214,-0.8034447431564331,-0.8034888505935669,-0.8034557700157166,-0.8034090399742126,-0.8034894466400146,-0.8034436702728271,-0.8034603595733643,-0.803437352180481,-0.8034164309501648,-0.8034213185310364,-0.8034321069717407,-0.8034634590148926,-0.8034276366233826,-0.8034191131591797,-0.8034197092056274,-0.8034776449203491,-0.803417980670929,-0.8034188151359558,-0.803445041179657,-0.8034418821334839,-0.8034310936927795,-0.8034186959266663,-0.8034548759460449,-0.8034701943397522,-0.8034445643424988,-0.803480863571167,-0.8034989237785339,-0.8034199476242065,-0.8034088611602783,-0.8034433126449585,-0.8034580945968628,-0.8034175634384155,-0.8034467697143555,-0.8034632802009583,-0.8034940361976624,-0.8034549951553345,-0.8034248948097229,-0.8034358620643616,-0.8034505248069763,-0.8034535646438599,-0.8034358620643616,-0.8034337162971497,-0.8034132122993469,-0.8034602403640747,-0.8034487366676331,-0.803485631942749,-0.8034313917160034,-0.8034185171127319,-0.8034237027168274,-0.8034420609474182,-0.8034241199493408,-0.8034301400184631,-0.8034716844558716,-0.8034146428108215,-0.8034886121749878,-0.8034127950668335,-0.8034713864326477,-0.8035038113594055,-0.8034217357635498,-0.8034202456474304,-0.8034136891365051,-0.8034787178039551,-0.8034310340881348,-0.8034277558326721,-0.8034424781799316,-0.8034200072288513,-0.8034318685531616,-0.8034107685089111,-0.8034471869468689,-0.8034518957138062,-0.803428590297699,-0.803432285785675,-0.8034467697143555,-0.8034346103668213,-0.8034408092498779,-0.8034053444862366,-0.8034465909004211,-0.8035099506378174,-0.8034173846244812,-0.8034383058547974,-0.8034270405769348,-0.8034622669219971,-0.803463339805603,-0.8034465909004211,-0.8034986257553101,-0.8034217357635498,-0.80345618724823,-0.8034354448318481,-0.8034216165542603,-0.8034444451332092,-0.8034294843673706,-0.8034858703613281,-0.8034535050392151,-0.8034478425979614,-0.8034284114837646,-0.8034636974334717,-0.803419291973114,-0.8034451007843018,-0.803449273109436,-0.8034682273864746,-0.803451418876648,-0.803437352180481,-0.8034388422966003,-0.8034276366233826,-0.8034725189208984,-0.803487241268158,-0.803409993648529,-0.8034234642982483,-0.8034308552742004,-0.8034619688987732,-0.8034488558769226,-0.8034355640411377,-0.8034358620643616,-0.8034241199493408,-0.8034345507621765,-0.8034839630126953,-0.8034217953681946,-0.8034355044364929,-0.8034868240356445,-0.8034509420394897,-0.8034580945968628,-0.803449273109436,-0.8034570217132568,-0.8034504055976868,-0.8034437298774719,-0.8034971356391907,-0.8034093379974365,-0.8034288883209229,-0.8034239411354065,-0.8034958243370056,-0.8034138679504395,-0.8034202456474304,-0.8034601807594299,-0.8034729957580566,-0.8034473657608032,-0.8034172654151917,-0.8034381866455078,-0.8034728169441223,-0.8034475445747375,-0.8034152388572693,-0.8034594058990479,-0.8034608960151672,-0.8034862875938416,-0.8034629821777344,-0.8034135103225708,-0.8034375905990601,-0.803464412689209,-0.8034731149673462,-0.8034382462501526,-0.8034955263137817,-0.8034177422523499,-0.8034482598304749,-0.8034359216690063,-0.803447961807251,-0.8035240769386292,-0.8034402132034302,-0.8034251928329468,-0.8034377098083496,-0.803412139415741,-0.8034380674362183,-0.8034523129463196,-0.8034268617630005,-0.8034894466400146,-0.8034282922744751,-0.8034248352050781,-0.8034199476242065,-0.8034658432006836,-0.803415834903717,-0.8034279942512512,-0.8034306168556213,-0.803455650806427,-0.8034747838973999,-0.803438663482666,-0.803409993648529,-0.8034406900405884,-0.8034258484840393,-0.8034104108810425,-0.8034405708312988,-0.8034483790397644,-0.803438663482666,-0.8034558892250061,-0.8034630417823792,-0.8034303188323975,-0.8034223914146423,-0.8034594655036926,-0.8034381866455078,-0.8034229278564453,-0.8034251928329468,-0.8034666180610657,-0.8034458160400391,-0.8034384250640869,-0.8034401535987854,-0.8034248948097229,-0.8034259676933289,-0.8034154772758484,-0.8035105466842651,-0.803467333316803,-0.8034157752990723,-0.8034475445747375,-0.8034459352493286,-0.8035078644752502,-0.8034461140632629,-0.8034163117408752,-0.8034679889678955,-0.8034403920173645,-0.8034296631813049,-0.8034375905990601,-0.8034496307373047,-0.8034239411354065,-0.803419291973114,-0.8034526109695435,-0.8034433126449585,-0.8034483194351196,-0.8034384250640869,-0.8034310936927795,-0.8034722805023193,-0.8034568428993225,-0.8034364581108093,-0.8034155368804932,-0.8034346699714661,-0.8034871220588684,-0.8034783005714417,-0.8035052418708801,-0.8034728169441223,-0.8034701347351074,-0.8034399151802063,-0.8034523725509644,-0.8034204244613647,-0.8034291863441467,-0.803440511226654,-0.8034430146217346,-0.8034180402755737,-0.8034778833389282,-0.8034132122993469,-0.8035145401954651,-0.8034403920173645,-0.8034899234771729,-0.8034111857414246,-0.8034694790840149,-0.8034620881080627,-0.803433358669281,-0.8034109473228455,-0.8034306168556213,-0.8034380078315735,-0.8034352660179138,-0.8034318685531616,-0.8034815788269043,-0.8035167455673218,-0.8034248352050781,-0.8034965395927429,-0.8034642338752747,-0.8034898638725281,-0.8034533262252808,-0.8034928441047668,-0.8034526705741882,-0.8035004734992981,-0.8034246563911438,-0.8034526705741882,-0.8034909963607788,-0.8034794926643372,-0.8034509420394897,-0.8034437894821167,-0.8034413456916809,-0.8034706711769104,-0.8034239411354065,-0.8034271597862244,-0.8034160733222961,-0.803443968296051,-0.8034257888793945,-0.803436815738678,-0.8034840226173401,-0.80348140001297,-0.8034594655036926,-0.8034607172012329,-0.8034451603889465,-0.8034601211547852,-0.8034801483154297,-0.8034498691558838,-0.8034498691558838,-0.803439736366272,-0.8034418225288391,-0.8035001754760742,-0.8034390211105347,-0.8034189939498901,-0.803425669670105,-0.8034560084342957,-0.8034254908561707,-0.8034200072288513,-0.8034594655036926,-0.8034704923629761,-0.8035027980804443,-0.8034303188323975,-0.8034214377403259,-0.8034533858299255,-0.8035032153129578,-0.8034501075744629,-0.8034264445304871,-0.8034447431564331,-0.8034502863883972,-0.8034197092056274,-0.8034560680389404,-0.8034408688545227,-0.8034375309944153,-0.8034294247627258,-0.8034229874610901,-0.8034343123435974,-0.8034700155258179,-0.8034682869911194,-0.803413987159729,-0.8034325838088989,-0.8034619092941284,-0.8034868240356445,-0.8034408688545227,-0.8034088611602783,-0.8034607172012329,-0.8034434914588928,-0.8034563064575195,-0.8034605383872986,-0.8034715056419373,-0.8034295439720154,-0.803411066532135,-0.8034270405769348,-0.8034213185310364,-0.8034518957138062,-0.8034481406211853,-0.8034458756446838,-0.8034321069717407,-0.8034485578536987,-0.8034614324569702,-0.8035043478012085,-0.8034490942955017,-0.8034889101982117,-0.8034835457801819,-0.803436815738678,-0.8035020232200623,-0.8034358620643616,-0.8034601211547852,-0.8034711480140686,-0.803423285484314,-0.8034495711326599,-0.8034383654594421,-0.8034332394599915,-0.8034883141517639,-0.8034160137176514,-0.8035296201705933,-0.8034157156944275,-0.8034329414367676,-0.8034243583679199,-0.8034617900848389,-0.8034377098083496,-0.803438663482666,-0.8034839630126953,-0.8034119606018066,-0.8034239411354065,-0.8034400343894958,-0.8034191131591797,-0.8034628629684448,-0.803431510925293,-0.8034271597862244,-0.8034724593162537,-0.8034179210662842,-0.8034346699714661,-0.8034155368804932,-0.8034493327140808,-0.803439199924469,-0.8035006523132324,-0.8034254908561707,-0.8034141659736633,-0.8034304976463318,-0.8034335374832153,-0.8034299612045288,-0.8034164905548096,-0.803480327129364,-0.8034871220588684,-0.8034217357635498,-0.8034278154373169,-0.8034815192222595,-0.8034369945526123,-0.803471565246582,-0.803443193435669,-0.8034343123435974,-0.8034448623657227,-0.8034608960151672,-0.8034149408340454,-0.8034955263137817,-0.8034849166870117,-0.8034214377403259,-0.8034602999687195,-0.803412139415741,-0.8034054636955261,-0.803435206413269,-0.8034693002700806,-0.8034499883651733,-0.8034763336181641,-0.8034104704856873,-0.8034894466400146,-0.8034383654594421,-0.8034076690673828,-0.8034650087356567,-0.803443193435669,-0.8034330606460571,-0.8034476637840271,-0.8034490942955017,-0.80340576171875,-0.8034241795539856,-0.8034664988517761,-0.8034206628799438,-0.8034242987632751,-0.8034157156944275,-0.8034095168113708,-0.8034368753433228,-0.8034381866455078,-0.8034866452217102,-0.8034506440162659,-0.8034804463386536,-0.8034175634384155,-0.8034365177154541,-0.8034338355064392,-0.8034812808036804,-0.8034371137619019,-0.8034325838088989,-0.8034036159515381,-0.8034326434135437,-0.8034541606903076,-0.8034593462944031,-0.8034668564796448,-0.8034517168998718,-0.8034363389015198,-0.8034408092498779,-0.8034475445747375,-0.8034458160400391,-0.8034523725509644,-0.8034272193908691,-0.8034566640853882,-0.8034599423408508,-0.8034412860870361,-0.8034331202507019,-0.8034119606018066,-0.8034722805023193,-0.8034759163856506,-0.803429365158081,-0.8034591674804688,-0.8035212755203247,-0.803451657295227,-0.803471565246582,-0.8034101724624634,-0.8034459352493286,-0.8034249544143677,-0.8034351468086243,-0.8034127950668335,-0.8034045100212097,-0.8034278154373169,-0.8034079074859619,-0.8034214377403259,-0.8034402132034302,-0.8034190535545349,-0.8034523129463196,-0.803418755531311,-0.8034243583679199,-0.8034223914146423,-0.8034346699714661,-0.8034241795539856,-0.8034154772758484,-0.8034108877182007,-0.8034220933914185,-0.8034512400627136,-0.8034783005714417,-0.8034401535987854,-0.8034939765930176,-0.8034209609031677,-0.8034911155700684,-0.8034208416938782,-0.8034526705741882,-0.8034430742263794,-0.8034570217132568,-0.8034996390342712,-0.8034183979034424,-0.8034723401069641,-0.8034347295761108,-0.8034476637840271,-0.803424596786499,-0.8034436702728271,-0.8034209609031677,-0.8034262657165527,-0.803429365158081,-0.8034657835960388,-0.8034369349479675,-0.8034199476242065,-0.8034688830375671,-0.8034771680831909,-0.8034801483154297,-0.8034270405769348,-0.8034408092498779,-0.8034544587135315,-0.8034465909004211,-0.8034183382987976,-0.8034168481826782,-0.8034449219703674,-0.803432822227478,-0.8034254908561707,-0.8034509420394897,-0.8034533262252808,-0.8034829497337341,-0.8034465909004211,-0.8034334182739258,-0.8034881353378296,-0.8034825921058655,-0.8034267425537109,-0.8034071922302246,-0.8034107685089111,-0.8034582138061523,-0.8034815192222595,-0.8034420609474182,-0.8034213185310364,-0.8034297227859497,-0.803452730178833,-0.8034782409667969,-0.8034461736679077,-0.8034718632698059,-0.8034405708312988,-0.8034757971763611,-0.8034313917160034,-0.8034284114837646,-0.8034301996231079,-0.80345618724823,-0.803413987159729,-0.8034916520118713,-0.8034394979476929,-0.8034850358963013,-0.8035195469856262,-0.8034958243370056,-0.8034014701843262,-0.8034735918045044,-0.8034456372261047,-0.8034483194351196,-0.8034801483154297,-0.803465723991394,-0.8034366965293884,-0.8034270405769348,-0.8034208416938782,-0.8034422397613525,-0.8034259676933289,-0.8034464716911316,-0.8034195899963379,-0.803416907787323,-0.8034291863441467,-0.8034585118293762,-0.8034167885780334,-0.8034378886222839,-0.8034161329269409,-0.8034038543701172,-0.8034105896949768,-0.8034566640853882,-0.8035091161727905,-0.8034220933914185,-0.8034543395042419,-0.8034475445747375,-0.8034517168998718,-0.8034931421279907,-0.8034291863441467,-0.8034640550613403,-0.8034417629241943,-0.8034409880638123,-0.8034167885780334,-0.8034384250640869,-0.8034613132476807,-0.8034228682518005,-0.8034177422523499,-0.8034343719482422,-0.803481936454773,-0.8034239411354065,-0.8034422993659973,-0.8034694790840149,-0.8034167885780334,-0.8034535050392151,-0.8034182190895081,-0.8034194707870483,-0.8034402132034302,-0.803432285785675,-0.8034467697143555,-0.8034096956253052,-0.8035098910331726,-0.8034628629684448,-0.8034157752990723,-0.8034489154815674,-0.8034178614616394,-0.8034301400184631,-0.8034490942955017,-0.8034732937812805,-0.8034722805023193,-0.8034404516220093,-0.803455114364624,-0.8034496903419495,-0.8034607172012329,-0.8034824728965759,-0.8034206628799438,-0.8034338355064392,-0.8034110069274902,-0.8034616112709045,-0.8034214377403259,-0.8034157156944275,-0.803505539894104,-0.8034505844116211,-0.8034945726394653,-0.8034310340881348,-0.8034377694129944,-0.8034914135932922,-0.8035176992416382,-0.8034239411354065,-0.8034388422966003,-0.8034818768501282,-0.8034233450889587,-0.8034936189651489,-0.8034533858299255,-0.8034447431564331,-0.8034366369247437,-0.80351722240448,-0.803437352180481,-0.8034529089927673,-0.8034300804138184,-0.8034538626670837,-0.8034310340881348,-0.8034626841545105,-0.8034491539001465,-0.8034284114837646,-0.8034443855285645,-0.8034886121749878,-0.8034163117408752,-0.8034176826477051,-0.8034740090370178,-0.8034300208091736,-0.8034384846687317,-0.8034552931785583,-0.8034523129463196,-0.8034383058547974,-0.8034133911132812,-0.803499698638916,-0.803432822227478,-0.8034257888793945,-0.8034198880195618,-0.8034326434135437,-0.8034380078315735,-0.8034853935241699,-0.8034533858299255],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"X\"}},\"yaxis\":{\"title\":{\"text\":\"Y\"}},\"zaxis\":{\"title\":{\"text\":\"Z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4f4fa33e-a637-428a-95d9-e5486fa0a8b8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "783QUNNoG2Pq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}