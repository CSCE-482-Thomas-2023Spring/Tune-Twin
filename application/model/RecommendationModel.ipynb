{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDApkkwOtG_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04a5a12-b0b8-4688-d35c-6df555bf28fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive so that training data can be used\n",
        "def mount_drive():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "mount_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Ih_0TDpsZsts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "import pandas as pd\n",
        "\n",
        "song_data = pd.read_csv(\"/content/drive/Shareddrives/Cop Detectors /Class Work/song_data/tracks_features.csv\")"
      ],
      "metadata": {
        "id": "IXbUCjUP1Eqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(song_data.columns)\n",
        "\n",
        "# process data to fit into feature set\n",
        "feature_list = ['acousticness',\n",
        "                'danceability',\n",
        "                'energy',\n",
        "                'key',\n",
        "                'liveness',\n",
        "                'loudness',\n",
        "                'tempo']\n",
        "features = song_data[feature_list]\n",
        "print(features.describe())\n",
        "\n",
        "# normalize data\n",
        "features = tf.keras.utils.normalize(features.values)\n",
        "\n",
        "# shuffle data\n",
        "np.random.shuffle(features)\n",
        "\n",
        "\n",
        "# reshape data into a training set\n",
        "slice_index = int(len(features)*0.8)\n",
        "x_train = features[:slice_index]\n",
        "x_test = features[slice_index:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNBHLuXQ1rZ7",
        "outputId": "3437b174-9ee3-47fc-99dd-000035daeafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'name', 'album', 'album_id', 'artists', 'artist_ids',\n",
            "       'track_number', 'disc_number', 'explicit', 'danceability', 'energy',\n",
            "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
            "       'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
            "       'time_signature', 'year', 'release_date'],\n",
            "      dtype='object')\n",
            "       acousticness  danceability        energy           key      liveness  \\\n",
            "count  1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06   \n",
            "mean   4.467511e-01  4.930565e-01  5.095363e-01  5.194151e+00  2.015994e-01   \n",
            "std    3.852014e-01  1.896694e-01  2.946839e-01  3.536731e+00  1.804591e-01   \n",
            "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "25%    3.760000e-02  3.560000e-01  2.520000e-01  2.000000e+00  9.680000e-02   \n",
            "50%    3.890000e-01  5.010000e-01  5.240000e-01  5.000000e+00  1.250000e-01   \n",
            "75%    8.610000e-01  6.330000e-01  7.660000e-01  8.000000e+00  2.450000e-01   \n",
            "max    9.960000e-01  1.000000e+00  1.000000e+00  1.100000e+01  1.000000e+00   \n",
            "\n",
            "           loudness         tempo  \n",
            "count  1.204025e+06  1.204025e+06  \n",
            "mean  -1.180870e+01  1.176344e+02  \n",
            "std    6.982132e+00  3.093705e+01  \n",
            "min   -6.000000e+01  0.000000e+00  \n",
            "25%   -1.525400e+01  9.405400e+01  \n",
            "50%   -9.791000e+00  1.167260e+02  \n",
            "75%   -6.717000e+00  1.370460e+02  \n",
            "max    7.234000e+00  2.489340e+02  \n",
            "(963220, 7)\n",
            "(240805, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised Model\n",
        "# In this case, an autoencoder.\n",
        "\n",
        "# We will take in the following features (for now):\n",
        "# acousticness (0.0 to 1.0)\n",
        "# danceability (0.0 to 1.0)\n",
        "# energy (0.0 to 1.0)\n",
        "# key (-1 to 11), 0 = C\n",
        "# liveness (0.0 to 1.0?)\n",
        "# loudness (-60dB to 0 dB)\n",
        "# tempo (BPM)\n",
        "\n",
        "\n",
        "\n",
        "# For now, using this dataset from Kaggle:\n",
        "# It has 1.2 million Spotify songs' features\n",
        "# https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs?resource=download\n",
        "\n",
        "\n",
        "# Each feature will be a node in the first layer\n",
        "# Each new layer will reduce the number of nodes by 1\n",
        "# So there will be a 7 node layer, then a 6 node layer, then 5, and so on # I'm not currently sure whether this approach is best for encoding, because\n",
        "# it could be the case that much information is lost if we go down to 1 layer,\n",
        "# to the point of it becoming useless.\n",
        "# Also, stepping down faster (like halving the number of nodes) might be better.\n",
        "# Then there will be a sequence of decoding the information back up to 7 dimensions\n",
        "# This is so that we can verify that the encoding maintained the original information\n",
        "# Otherwise we could not train the model weights.\n",
        "\n",
        "# We can play with and research different architectures.\n",
        "\n",
        "\n",
        "# using this resource: https://towardsdatascience.com/unsupervised-machine-learning-example-in-keras-8c8bf9e63ee0\n",
        "# and https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "# and MAINLY https://www.tensorflow.org/tutorials/generative/autoencoder\n",
        "\n",
        "# latent dimensions: The number of dimensions in the compressed representation\n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(7, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(5, activation='tanh'),\n",
        "        layers.Dense(4, activation='tanh'),\n",
        "        layers.Dense(3, activation='tanh'),\n",
        "        #layers.Dense(2, activation='tanh'),\n",
        "        #layers.Dense(1, activation='tanh'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "        #layers.Dense(1, activation='tanh'),\n",
        "        #layers.Dense(2, activation='tanh'),\n",
        "        layers.Dense(3, activation='tanh'),\n",
        "        layers.Dense(4, activation='tanh'),\n",
        "        layers.Dense(5, activation='tanh'),\n",
        "        layers.Dense(6, activation='tanh'),\n",
        "        layers.Dense(7, activation='tanh')\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder()"
      ],
      "metadata": {
        "id": "flbPTmZcvzm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', \n",
        "                    loss=losses.MeanAbsoluteError(),\n",
        "                    metrics=[[\"accuracy\",]])"
      ],
      "metadata": {
        "id": "Z8Ix2jn0gZxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QUBVbKn4Dpk",
        "outputId": "8d6d7591-6953-4c03-c5d0-cc8c883d83b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24081/24081 [==============================] - 134s 5ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 2/10\n",
            "24081/24081 [==============================] - 134s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "Epoch 3/10\n",
            "24081/24081 [==============================] - 125s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 4/10\n",
            "24081/24081 [==============================] - 126s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "24081/24081 [==============================] - 123s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 6/10\n",
            "24081/24081 [==============================] - 122s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 7/10\n",
            "24081/24081 [==============================] - 133s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
            "Epoch 8/10\n",
            "24081/24081 [==============================] - 124s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
            "Epoch 9/10\n",
            "24081/24081 [==============================] - 128s 5ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
            "Epoch 10/10\n",
            "24081/24081 [==============================] - 126s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 0.9998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf10451a90>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.evaluate(x_test, x_test)"
      ],
      "metadata": {
        "id": "5Y5CBtUqt6I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de62b45-afd6-4f1c-aaec-a9892c6f6d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7526/7526 [==============================] - 19s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0012416772078722715, 0.9997342228889465]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test[0])\n",
        "print(x_test[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn9GBMXK-1hx",
        "outputId": "713a74eb-3e80-4a5e-f20e-f756debadb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.64446044e-04  6.29727032e-03  5.37761946e-03  3.89682570e-02\n",
            "  9.35238167e-04 -5.50387661e-02  9.97688695e-01]\n",
            "(7,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.predict(x_test[0].reshape((1,-1)))"
      ],
      "metadata": {
        "id": "o2HBNwft3NO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5edf804-178f-4d30-f834-c650fa0ba939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 138ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-7.0035458e-07,  5.1448965e-03,  5.0501688e-03,  3.8452845e-02,\n",
              "         1.0078619e-03, -5.4043271e-02,  9.9710858e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: PCA (preferred) or t-SNE on the features + the outputted feature(s) \n",
        "# from the unsupervised model, for dimensionality reduction"
      ],
      "metadata": {
        "id": "GSqDT3yeXlXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Nearest Neighbor Search algorithm in feature space"
      ],
      "metadata": {
        "id": "3YWC_nZ4X3Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape = (x_train.shape[0], x_train.shape[1]))\n",
        "x = layers.Bidirectional(layers.LSTM(16))(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer = \"rmsprop\", loss = \"mse\", metrics = [\"mae\"])\n",
        "print(x_train.shape)\n",
        "history = model.fit(x_train, epochs = 10, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "tPM3jrAK1FXF",
        "outputId": "c7eea089-b7be-4613-d4a0-21dbad3c7e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(963220, 7)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d41103696f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_2\" is incompatible with the layer: expected shape=(None, 963220, 7), found shape=(None, 7)\n"
          ]
        }
      ]
    }
  ]
}